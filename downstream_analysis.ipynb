{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment: napari_sparrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari_sparrow as nas\n",
    "import sparrow as sp\n",
    "import os\n",
    "import spatialdata as sd\n",
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from skimage import io\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import spatialdata as sd\n",
    "import pandas as pd\n",
    "from sparrow.table._table import _back_sdata_table_to_zarr\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from skimage.measure import regionprops_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to root folder\n",
    "root_folder = 'D:/Data/2023-07-CarolineAsselman-FIm/Analysis_v2'\n",
    "\n",
    "# Specify ROI name\n",
    "ROI = 'A1_ROI1'\n",
    "\n",
    "# Path to input folders\n",
    "images_path = os.path.join(root_folder, 'cropped_images', ROI)\n",
    "regions_path = os.path.join(root_folder, 'Qupath_annotations', ROI)\n",
    "masks_path = os.path.join(root_folder, 'output', ROI, 'segmentation/masks')\n",
    "ilastik_path = os.path.join(root_folder, 'output/ilastik')\n",
    "\n",
    "# Path to output folders\n",
    "output_path = os.path.join(root_folder, 'output', ROI, 'downstream_analysis')\n",
    "plots_path = os.path.join(output_path, 'plots')\n",
    "tables_path = os.path.join(output_path, 'tables')\n",
    "os.makedirs(output_path, exist_ok = True)\n",
    "os.makedirs(plots_path, exist_ok = True)\n",
    "os.makedirs(tables_path, exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify channels to read in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gene_lists import keep, omitted_channels, immune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "c_coords_list = []\n",
    "\n",
    "def create_input_lists(channel_list):\n",
    "    for file in os.listdir(images_path):\n",
    "        if (file.endswith('.tif') or file.endswith('tiff')) and any(channel in file for channel in channel_list):\n",
    "            input_list.append(os.path.join(images_path, file))\n",
    "            filename = os.path.splitext(file)[0]\n",
    "            channel_name = [channel for channel in channel_list if channel in filename]\n",
    "            c_coords_list.append(' '.join(channel_name))\n",
    "        \n",
    "create_input_lists(keep+omitted_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or read sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.io.create_sdata(\n",
    "    input= input_list,\n",
    "    c_coords= c_coords_list,\n",
    "    output_path=os.path.join(output_path, \"sdata.zarr\"),\n",
    "    img_layer=\"raw_image\",\n",
    "    chunks=1024)\n",
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdata = sd.read_zarr(os.path.join(output_path, \"sdata.zarr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image', \n",
    "    channel = 'DAPI', \n",
    "    output=os.path.join(plots_path , 'DAPI.png'),\n",
    "    vmin_img=0,\n",
    "    vmax_img=65535,\n",
    "    alpha=0.3,\n",
    "    figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add region annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_regions = gpd.read_file(os.path.join(regions_path, 'regions.geojson'))\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=gdf_regions, output_layer='regions', overwrite=True)\n",
    "\n",
    "gdf_regions_grouped = gdf_regions.groupby('name')\n",
    "for name, group in gdf_regions_grouped:\n",
    "    sdata = sp.sh._add_shapes_layer(sdata, input=group, output_layer=f'regions_{name}', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image', \n",
    "    channel = 'DAPI', \n",
    "    shapes_layer = 'regions',\n",
    "    output=os.path.join(plots_path , 'DAPI_regions.png'),\n",
    "    vmin_img=0,\n",
    "    vmax_img=65535,\n",
    "    alpha=0.3,\n",
    "    figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in gdf_regions_grouped:    \n",
    "    sp.pl.plot_shapes(\n",
    "        sdata, \n",
    "        img_layer='raw_image', \n",
    "        channel = 'DAPI', \n",
    "        shapes_layer = f'regions_{name}',\n",
    "        output=os.path.join(plots_path , f'DAPI_{name}.png'),\n",
    "        vmin_img=0,\n",
    "        vmax_img=65535,\n",
    "        alpha=0.3,\n",
    "        figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add artifacts annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_artifacts = gpd.read_file(os.path.join(regions_path, 'artifacts.geojson'))\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=gdf_artifacts, output_layer='artifacts', overwrite=True)\n",
    "\n",
    "gdf_artifacts_grouped = gdf_artifacts.groupby('name')\n",
    "for name, group in gdf_artifacts_grouped:\n",
    "    sdata = sp.sh._add_shapes_layer(sdata, input=group, output_layer=f'artifacts_{name}', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image', \n",
    "    channel = 'DAPI', \n",
    "    shapes_layer = 'artifacts',\n",
    "    output=os.path.join(plots_path , 'DAPI_artifacts.png'),\n",
    "    vmin_img=0,\n",
    "    vmax_img=65535,\n",
    "    alpha=0.3,\n",
    "    figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, group in gdf_artifacts_grouped:    \n",
    "    sp.pl.plot_shapes(\n",
    "        sdata, \n",
    "        img_layer='raw_image', \n",
    "        channel = 'DAPI', \n",
    "        shapes_layer = f'artifacts_{name}',\n",
    "        output=os.path.join(plots_path , f'DAPI_{name}.png'),\n",
    "        vmin_img=0,\n",
    "        vmax_img=65535,\n",
    "        alpha=0.3,\n",
    "        figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add segmentation masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mask = io.imread(os.path.join(masks_path, 'segmentation_mask_merged.tiff'))\n",
    "nucleus_mask = io.imread(os.path.join(masks_path, 'segmentation_mask_nucleus.tiff'))\n",
    "expanded_nucleus_mask = io.imread(os.path.join(masks_path, 'segmentation_mask_expanded_nucleus.tiff'))\n",
    "immune_mask = io.imread(os.path.join(masks_path, 'segmentation_mask_immune.tiff'))\n",
    "RBC_mask = io.imread(os.path.join(masks_path, 'segmentation_mask_RBC.tiff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.im._add_label_layer(sdata, arr=merged_mask, chunks=1024, output_layer=\"segmentation_mask_merged\")\n",
    "sdata = sp.im._add_label_layer(sdata, arr=nucleus_mask, chunks=1024, output_layer=\"segmentation_mask_nucleus\")\n",
    "sdata = sp.im._add_label_layer(sdata, arr=expanded_nucleus_mask, chunks=1024, output_layer=\"segmentation_mask_expanded_nucleus\")\n",
    "sdata = sp.im._add_label_layer(sdata, arr=immune_mask, chunks=1024, output_layer=\"segmentation_mask_immune\")\n",
    "sdata = sp.im._add_label_layer(sdata, arr=RBC_mask, chunks=1024, output_layer=\"segmentation_mask_RBC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.sh._add_shapes_layer(sdata, input=sdata[\"segmentation_mask_merged\"].data, output_layer=\"segmentation_mask_merged_boundaries\", transformation=None, overwrite=True)\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=sdata[\"segmentation_mask_nucleus\"].data, output_layer=\"segmentation_mask_nucleus_boundaries\", transformation=None, overwrite=True)\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=sdata[\"segmentation_mask_expanded_nucleus\"].data, output_layer=\"segmentation_mask_expanded_nucleus_boundaries\", transformation=None, overwrite=True)\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=sdata[\"segmentation_mask_immune\"].data, output_layer=\"segmentation_mask_immune_boundaries\", transformation=None, overwrite=True)\n",
    "sdata = sp.sh._add_shapes_layer(sdata, input=sdata[\"segmentation_mask_RBC\"].data, output_layer=\"segmentation_mask_RBC_boundaries\", transformation=None, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata['raw_image'].c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_spatialdata import Interactive\n",
    "Interactive(sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intensity allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.tb.allocate_intensity(\n",
    "        sdata, img_layer=\"raw_image\", labels_layer=\"segmentation_mask_merged\", channels=keep+omitted_channels, chunks=4000, append=False, append_labels_layer_name=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove index 0\n",
    "table = sdata.table[sdata.table.obs.index != '0']\n",
    "del sdata.table\n",
    "sdata.table = sd.models.TableModel.parse(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regionprops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata = sp.tb.add_regionprop_features(\n",
    "    sdata, labels_layer=\"segmentation_mask_merged\", append_labels_layer_name=False)\n",
    "\n",
    "sdata = sp.tb.add_regionprop_features(\n",
    "    sdata, labels_layer=\"segmentation_mask_nucleus\", append_labels_layer_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean sdata.table.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.obs = (\n",
    "    sdata.table.obs\n",
    "    # Strip underscores from column names\n",
    "    .rename(columns=lambda x: x.lstrip('_'))\n",
    "    # Change names of centroid columns\n",
    "    .rename(columns={\n",
    "        'centroid-0': 'centroid_y',\n",
    "        'centroid-1': 'centroid_x', \n",
    "        'centroid-0_nucleus': 'centroid_y_nucleus', \n",
    "        'centroid-1_nucleus': 'centroid_x_nucleus'\n",
    "    })\n",
    "    # Change names of nucleus columns\n",
    "    .rename(columns=lambda x: x.replace('_segmentation_mask_nucleus', '_nucleus'))\n",
    ")\n",
    "_back_sdata_table_to_zarr(sdata=sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine whether cell has nucleus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.obs['nucleus'] = sdata.table.obs['area_nucleus'] > 0\n",
    "_back_sdata_table_to_zarr(sdata=sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.obs['nucleus'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign cells to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to assign cells to regions\n",
    "def assign_region(centroid, gdf):\n",
    "    for index, row in gdf.iterrows():\n",
    "        if Point(centroid).within(row['geometry']):\n",
    "            return row['name']\n",
    "    return 'Not_assigned'\n",
    "\n",
    "# Define function to calculate distance to region\n",
    "def calculate_distance(centroid, gdf):\n",
    "    return gdf.distance(Point(centroid)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cells\n",
    "sdata.table.obs = (\n",
    "    sdata.table.obs\n",
    "    # Assign for each cell centroid in which region it occurs\n",
    "    .assign(\n",
    "        region_annotation = lambda x: x.apply(\n",
    "            lambda row: assign_region((row['centroid_x'], row['centroid_y']), sdata.shapes['regions']), axis=1))\n",
    "    # Assign for each cell centroid whether it occurs in an artifact\n",
    "    .assign(\n",
    "        artifact_annotation = lambda x: x.apply(\n",
    "            lambda row: assign_region((row['centroid_x'], row['centroid_y']), sdata.shapes['artifacts']), axis=1))\n",
    "    # Calculate distance to edge of lumen\n",
    "    .assign(\n",
    "        distance_to_lumen = lambda x: x.apply(\n",
    "            lambda row: calculate_distance((row['centroid_x'], row['centroid_y']), sdata.shapes['regions_lumen']), axis=1))\n",
    ")\n",
    "_back_sdata_table_to_zarr(sdata=sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.obs['region_annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.obs['artifact_annotation'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add original segmentation mask labels and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparrow.image.segmentation._utils import _mask_to_original\n",
    "df_masks=_mask_to_original(sdata, label_layer=\"segmentation_mask_merged\", original_labels_layers=[ \"segmentation_mask_immune\", \"segmentation_mask_RBC\",  \"segmentation_mask_expanded_nucleus\"] )\n",
    "df_masks['original_segmentation_mask'] = df_masks.idxmax(axis=1)\n",
    "sdata.table.obs = sdata.table.obs.merge(df_masks, left_index=True, right_index=True, how='inner')\n",
    "_back_sdata_table_to_zarr(sdata=sdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = pd.pivot_table(\n",
    "    sdata.table.obs,\n",
    "    index='original_segmentation_mask', \n",
    "    values='nucleus', \n",
    "    aggfunc=['count', lambda x: x.sum()])\n",
    "pivot_table.columns = ['cell_count', 'nucleus_count']\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate average intensity and add to sdata.table.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns with total intensities to obs\n",
    "intensity_df = sdata.table.to_df()\n",
    "sdata.table.obs = pd.merge(sdata.table.obs, intensity_df, left_index=True, right_index=True, how=\"left\")\n",
    "\n",
    "# Correct intensities for area\n",
    "for channel in keep+omitted_channels:\n",
    "    sdata.table.obs[f'{channel}_average_intensity'] = sdata.table.obs[channel] / sdata.table.obs['area']\n",
    "\n",
    "# Drop columns with total intensities\n",
    "columns_to_remove = [f\"{channel}\" for channel in keep+omitted_channels]\n",
    "sdata.table.obs = sdata.table.obs.drop(columns=columns_to_remove)\n",
    "\n",
    "_back_sdata_table_to_zarr(sdata=sdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some plots of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image',\n",
    "    channel = 'DAPI',\n",
    "    shapes_layer=\"segmentation_mask_merged_boundaries\", \n",
    "    output=os.path.join(plots_path , 'merged_masks_0_segmentation_masks.png'),\n",
    "    alpha=1,\n",
    "    cmap='rainbow',\n",
    "    column='original_segmentation_mask',\n",
    "    figsize=(35,22.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image',\n",
    "    channel = 'DAPI',\n",
    "    shapes_layer=\"segmentation_mask_merged_boundaries\", \n",
    "    output=os.path.join(plots_path , 'merged_masks_1_nucleus.png'),\n",
    "    alpha=1,\n",
    "    cmap='rainbow',\n",
    "    column='nucleus',\n",
    "    figsize=(35,22.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image',\n",
    "    channel = 'DAPI',\n",
    "    shapes_layer=\"segmentation_mask_merged_boundaries\", \n",
    "    output=os.path.join(plots_path , 'merged_masks_3_artifact_annotation.png'),\n",
    "    alpha=1,\n",
    "    cmap='Paired',\n",
    "    column='artifact_annotation',\n",
    "    figsize=(35,22.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.pl.plot_shapes(\n",
    "    sdata, \n",
    "    img_layer='raw_image',\n",
    "    channel = 'DAPI',\n",
    "    shapes_layer=\"segmentation_mask_merged_boundaries\", \n",
    "    output=os.path.join(plots_path , 'merged_masks_4_region_annotation.png'),\n",
    "    alpha=1,\n",
    "    cmap='rainbow',\n",
    "    column='region_annotation',\n",
    "    figsize=(35,22.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots of average intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_intensity_path = os.path.join(plots_path, \"average_intensity_plots_all\")\n",
    "os.makedirs(average_intensity_path, exist_ok = True)\n",
    "\n",
    "for channel in keep+omitted_channels:\n",
    "    sp.pl.plot_shapes(\n",
    "        sdata, \n",
    "        img_layer='raw_image',\n",
    "        channel = 'DAPI',\n",
    "        shapes_layer=\"segmentation_mask_merged_boundaries\", \n",
    "        output=os.path.join(average_intensity_path , f'average_intensity_{channel}.png'),\n",
    "        alpha=1,\n",
    "        cmap='viridis',\n",
    "        column=f\"{channel}_average_intensity\",\n",
    "        figsize=(35,22.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immune cells analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Incorporating ilastik object classifiers and create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import glob\n",
    "\n",
    "def preprocess_ilastik_csv(sdata, ilastik_csv_path):\n",
    "    # Read and filter ilastik table\n",
    "    ilastik_df = pd.read_csv(ilastik_csv_path)\n",
    "    ilastik_df = ilastik_df[ilastik_df['Size in pixels'] >= sdata.table.obs['area'].min()] # This step attempts to remove all erroneous small objects created by ilastik that do no match to cell objects\n",
    "    \n",
    "    # Renaming columns\n",
    "    ilastik_df.rename(columns={\n",
    "        'User Label': 'ilastik_user_label',\n",
    "        'Predicted Class': 'ilastik_predicted_class',\n",
    "        'Center of the object_0': 'ilastik_centroid_x',\n",
    "        'Center of the object_1': 'ilastik_centroid_y'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Renaming probability columns\n",
    "    probability_columns = [col for col in ilastik_df.columns if col.startswith('Probability of')]\n",
    "    for col in probability_columns:\n",
    "        new_col_name = f'ilastik_probability_{col.split(\" \")[-1]}'\n",
    "        ilastik_df.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "    # Selecting the columns to keep\n",
    "    columns_to_keep = [\n",
    "        'ilastik_user_label',\n",
    "        'ilastik_predicted_class',\n",
    "        'ilastik_centroid_x',\n",
    "        'ilastik_centroid_y'\n",
    "    ] + [col for col in ilastik_df.columns if col.startswith('ilastik_probability_')]\n",
    "\n",
    "    ilastik_df = ilastik_df[columns_to_keep]\n",
    "    \n",
    "    # Rename cells without user labels\n",
    "    class_names = ilastik_df['ilastik_predicted_class'].unique()\n",
    "    \n",
    "    for index, row in ilastik_df.iterrows():\n",
    "        ilastik_user_label = row['ilastik_user_label']\n",
    "        if ilastik_user_label not in class_names:\n",
    "            ilastik_df.at[index, 'ilastik_user_label'] = 'no_user_label'\n",
    "    \n",
    "    # Get ilastik nickname from file name\n",
    "    filename = os.path.basename(ilastik_csv_path)\n",
    "    filename_no_ext = os.path.splitext(filename)[0]\n",
    "    \n",
    "    if '_table' in filename_no_ext:\n",
    "        csv_name = filename_no_ext.replace('_table', '')\n",
    "    else:\n",
    "        csv_name = filename_no_ext\n",
    "    \n",
    "    return ilastik_df, csv_name\n",
    "\n",
    "def return_ilastik_data_for_nearest_cell(row, ilastik_df):\n",
    "    # Extract coordinates\n",
    "    adata_coordinates = (row['centroid_x'], row['centroid_y'])\n",
    "    ilastik_coordinates = ilastik_df[['ilastik_centroid_x', 'ilastik_centroid_y']]\n",
    "\n",
    "    # Calculate distances\n",
    "    distances = cdist([adata_coordinates], ilastik_coordinates)[0]\n",
    "\n",
    "    # Find nearest neighbor\n",
    "    nearest_neighbor_index = np.argmin(distances)\n",
    "    nearest_neighbor = ilastik_df.iloc[nearest_neighbor_index]\n",
    "\n",
    "    return nearest_neighbor\n",
    "\n",
    "def add_ilastik_to_sdata(sdata, ilastik_df, suffix=None):\n",
    "    # Match ilastik objects to sdata objects\n",
    "    merged_data = sdata.table.obs.apply(\n",
    "        return_ilastik_data_for_nearest_cell,\n",
    "        axis = 1, \n",
    "        ilastik_df = ilastik_df)\n",
    "    merged_data = merged_data.drop(columns=['ilastik_centroid_x', 'ilastik_centroid_y'])\n",
    "    if suffix is not None:\n",
    "        merged_data.columns = [col + '_' + suffix for col in merged_data.columns]\n",
    "\n",
    "    # Add ilastik data to sdata.table.obs\n",
    "    table = sdata.table.obs\n",
    "    for col in merged_data.columns:\n",
    "        table[col] = merged_data[col]\n",
    "    sdata.table.obs = table\n",
    "    _back_sdata_table_to_zarr(sdata=sdata)\n",
    "\n",
    "# Add data from all ilastik csv files in folder to sdata\n",
    "ilastik_classifiers_data = {}\n",
    "\n",
    "for ilastik_csv_path in glob.glob(f'{ilastik_path}/*_{ROI}_table.csv'):\n",
    "    print(ilastik_csv_path)\n",
    "    \n",
    "    ilastik_df, csv_name = preprocess_ilastik_csv(sdata, ilastik_csv_path)\n",
    "    csv_name = csv_name.replace(f'_{ROI}', '')\n",
    "    ilastik_classifiers_data[csv_name] = ilastik_df\n",
    "\n",
    "    add_ilastik_to_sdata(sdata, ilastik_df, suffix = csv_name)\n",
    "    \n",
    "# NOTE: This code will attempt to merge the data obtained from the ilastik classifiers to the sdata.tabel.obs based on the centroid coordinates of the sdata cells and the ilastik objects (i.e. for each cell in the sdata, the closest cell in the ilastik data will be considered a match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots per ilastik classifier\n",
    "for csv_name in ilastik_classifiers_data:\n",
    "    \n",
    "    plots_path_ilastik = os.path.join(plots_path, 'ilastik_classifiers', csv_name)\n",
    "    os.makedirs(plots_path_ilastik, exist_ok=True)\n",
    "    \n",
    "    class_names = ['pos', 'neg']\n",
    "    probability_columns = [col for col in sdata.table.obs.columns if col.startswith('ilastik_probability_') and any(col.endswith(f\"_{name}_{csv_name}\") for name in class_names)]\n",
    "    \n",
    "    for column in sdata.table.obs.columns:\n",
    "        if column == f'ilastik_user_label_{csv_name}' or column == f'ilastik_predicted_class_{csv_name}':\n",
    "            sp.pl.plot_shapes(\n",
    "                sdata, \n",
    "                img_layer='raw_image', \n",
    "                channel='DAPI', \n",
    "                shapes_layer='segmentation_mask_merged_boundaries',\n",
    "                output=f'{plots_path_ilastik}/{column}.png',\n",
    "                alpha=1,\n",
    "                cmap='rainbow',\n",
    "                column=column,\n",
    "                figsize=(35,22.5))\n",
    "            \n",
    "        if column in probability_columns:\n",
    "            sp.pl.plot_shapes(\n",
    "                sdata, \n",
    "                img_layer='raw_image', \n",
    "                channel='DAPI', \n",
    "                shapes_layer='segmentation_mask_merged_boundaries',\n",
    "                output=f'{plots_path_ilastik}/{column}.png',\n",
    "                alpha=1,\n",
    "                cmap='viridis',\n",
    "                column=column,\n",
    "                figsize=(35,22.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells = sdata.table.obs\n",
    "df_cells.to_csv(os.path.join(tables_path, \"cells_table.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_x = sdata.table.obs['centroid_x']\n",
    "centroid_y = sdata.table.obs['centroid_y']\n",
    "coordinates_array = np.column_stack((centroid_x, centroid_y))\n",
    "sdata.table.obsm[\"spatial\"] = coordinates_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdata.table.write_h5ad(filename=os.path.join(tables_path, \"anndata.h5ad\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesmer_sparrow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
